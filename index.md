
*RWL = Read Watch Learn*

# Agust 1, 2024

I am back!

## Theory of uncertainty? 

What is the right theory of uncertainty--the right inference engine that allows us to form beliefs and reach conclusions about events, facts and hypotheses that are uncertain? Clearly probability theory has to play a role. Bayesianism is the theory? But that does not seem right. The main objection I see comes from **small worlds** or **unanticipated possibilities**. You calculate probabilities given a small world--say a game of chance, with fixed sample space and clearly defined rules governing the production of outcomes? Clearly probability applies there. And it is an excellent guide.

But you might have forgotten, not considered certain possibilities. Or these possibilities might not be salient to you at the time you construct your small world model relative to which you calculate the probabilities. So how can these probabilities be action-guiding? They are model relative. They say: If the world is like the model, then the chances are like this. But what if the world is *not* like the model? Then, what? Then, the probabilities can be wrong and get you astray. 

This might not seem a bit problem. Everything, after all, is model relative. If the model is wrong, then the reccomendations coming from the model are wrong. The same applies to data. I base my decisions on data, but the data can be wrong or fabricated or whatever, and if so, then I am in trouble if I follow the data! But this does not mean I should *not* follow the data. So what is the problem with probabilities then?

Well, the inferences and decisions we make are not made in a small world, but the real world---the *big* world. So a theory of uncertainity should operate in the big world, not in a small world. It would be an incomplete theory of uncertainty if it were limited to small worlds. So the problem is, Bayesianim is a good theory of uncertainty in small worlds, but what about the big world? 

This question becomes pressing as we look at other domain besides small worlds. What about law, finance, medicine or even personal life decisions? Even in science, say physics, it does not seem probability---Bayesianism---gives us a good account of what is going on. 

In **law**, the most penetrating critique of Bayesianism is by Ron Allen. I know his work, but it would be good to get his objections all in one place.

In **economics**, monetary policy and social science, this book seems good as a critique of Bayesianism:

- John Kay and Mervyn King (2020), [Radical Uncertainty](https://www.amazon.com/Radical-Uncertainty-Decision-Making-Beyond-Numbers/dp/1324004770)

In philosopbhy of **science**, here is a survey article:

- John Norton, [Challenges to Bayesian confirmation theory](https://sites.pitt.edu/~jdnorton/papers/Challenges_final.pdf)

How do **financial planners** make decisions? What guiding principles of uncertainty do they follow? Are they just guided by probabilities and expected utility?

# August 6, 2024

## Rootclaim debate about the origins of Covid-19

Rootclaim holds that covid spread because of a lab leak. It bet usd 100,000 this was the right claim and anyone who wanted to challange them was free to do it. Peter Miller did and [won](https://blog.rootclaim.com/rootclaims-covid-19-origins-debate-results/)! He defended the view that covid came from animals, possibly from bats to civets sold in the Wuhan wildlife market. I've started watching the debate. It is very interesting.

The debate is relevant for my earlier question, what is the right theory of uncertainty---the right inference engine that allows us to form beliefs and reach conclusions about events, facts and hypotheses that are uncertain? Rootclaim did a probabilistic analysis. Peter Miller, instead, did what we might call a fact-focused narrative analysis. He collected as many facts as reasonably available, put them together, compared the strengths of the two competing theories (animal origin versus lab leak) and concluded that the lab leak theory had to posit many more coincidences than the animal origin theory. It seems Peter Milller thought the animal origin theory explains the evidence/facts we have better than the lab leak theory does. Rootclaim might not disagree with that, but still hold that the lab leak theory is more probable overall. So what is the criterion to follow? Explanatory power or likelihood of truth? 

One of the judges in the debate wrote (in a blog [entry](https://ermsta.com/posts/20240301)) probability theory is not the right framework to assess the evidence. He still provided a probabilistic analysis, but did not think it was dispositive:

> I was concerned that people might interpret my Bayesian analysis as the “main product” of the report, in isolation from the rest, which is why I heavily cautioned against taking it too literally; indeed I explicitly state that I do not think it is an appropriate technique for this problem, and am only producing one because it feels fair to do so after criticizing Rootclaim’s analysis.

Interesting! His very detailed analysis is below:

- Eric Stansifer, [Rootclaim covid-19 origins debate: Final decision](https://ermsta.com/r/covid_decision_20240217.pdf)

I need to read it carefully, and see why Eric thought Bayesianism is not the right (or not the ultimate?) guide for 
judging the debate about the origins of covid. But the clash between explanatory power versus and likelihood of a story is reminiscient of debates in legal scholarship, between legal probabilists/Bayesians and Ronald Allen who prefers relative plausibility. 

## ACLU on Trump Excutive Order on DEI and Florida HB7 bill

ACLU wrote a memo about [Trump on DEI and anti-discrmination law](https://assets.aclu.org/live/uploads/2024/07/Memo_Trump_DEI_v4.pdf). It is a good read, informative and well-researched, but I was confused by some of the presentation, tone and overall argument.  Consider this claim:

> A second Trump administration would supercharge efforts to censor discussion of any concepts deemed
“divisive” from the nation’s classrooms, by which it means classroom discussions about race, gender, and systemic
oppression with which it disagrees. (p. 2).

What the ACLU claims here might be true as a matter of fact---that is, this might very well be what Trum has actually in mind---but we should look at the evidence and the historical record. So what comes to mind is the executive order banning DEI (actually, [Executive Order Combating Race and Sex Stereotyping](https://trumpwhitehouse.archives.gov/presidential-actions/executive-order-combating-race-sex-stereotyping/) issued in September 2020). In it (Section 2), we find a list of "divise concepts" . Here it is:

> (a) “Divisive concepts” means the concepts that (1) one race or sex is inherently superior to another race or sex; (2) the United States is fundamentally racist or sexist; (3) an individual, by virtue of his or her race or sex, is inherently racist, sexist, or oppressive, whether consciously or unconsciously; (4) an individual should be discriminated against or receive adverse treatment solely or partly because of his or her race or sex; (5) members of one race or sex cannot and should not attempt to treat others without respect to race or sex; (6) an individual’s moral character is necessarily determined by his or her race or sex; (7) an individual, by virtue of his or her race or sex, bears responsibility for actions committed in the past by other members of the same race or sex; (8) any individual should feel discomfort, guilt, anguish, or any other form of psychological distress on account of his or her race or sex; or (9) meritocracy or traits such as a hard work ethic are racist or sexist, or were created by a particular race to oppress another race. The term “divisive concepts” also includes any other form of race or sex stereotyping or any other form of race or sex scapegoating.

If you did not know this list came from the infamous executive order, you probably would disagree with most, if not all the items in the list. Who would agree that (1) one race is superior to another? Only racists would. Who would agree that (3) people, just becaue of their race, are racist? Who would agree that (4) people should be discriminated against because of their race? Who would agree that (6) one's moral character is determined by their race? And so on. Many (all?) of these claims are certainly "divisive" and quite simply morally abhorrent.

The divisive concepts listed in the exective order are not "classroom discussions about race, gender, and systemic
oppression", as the ACLU memo suggests. They are, as the order names them, divisive. Now, as I said, Trump might actually want to prohibit any discussion about race, racism or structural oppression. Some of his voters might want that. But this is not what the executive order says. So the framing of the issue by the ACLU seems misleading. 

After the executive order came out in September 2020, the Berkeley Center of Othering and Belonging--whose mission "to build a world where everyone belongs" sounds great---[commented](https://belonging.berkeley.edu/why-trumps-diversity-training-ban-unconstitutional) as follows:

> The Executive Order grossly misrepresents the nature of Diversity, Equity and Inclusion training. As someone who has conducted or helped prepare countless such trainings, I have never made such claims or anything close to such claims. Most of my training materials include data, facts, figures, laws and policies, and recommendations for reform or policy change. In fact, saying that a person is inherently superior because of their race or sex is not only antithetical to the concept of equity, it is one of the definitions of racism. It would be absurd for an antiracist training to trade in such claims.

If no DEI practioner would push the divise concepts in the executive order, the order does not target DEI initiatives, and DEI practioners have nothing to fear, right? Some will say this conclusion is naive. Granted, the order likely has a chilling effect. DEI practioners for fear of litigigation against them might self-censor even though they do not actually profess divisive concepts. This is certainly a risk that should not be overestimated. 

Still, on its face, the order targets not DEI as such, but at most DEI so long as it is divisive. The question becomes an emprical one. Do DEI practioners actually push diviside concepts? If they don't, as the Berkeley Center of Othering and Belonging attests, the order on its face cannot target DEI. 

Let's now look at the Florida HB7 which has a similar intent. The key bit is this:

> 760.10 Unlawful employment practices.—
> 8)(a) Subjecting any individual, as a condition of
> employment, membership, certification, licensing, credentialing,
> or passing an examination, to training, instruction, or any
> other required activity that espouses, promotes, advances,
> inculcates, or compels such individual to believe any of the
> following concepts constitutes discrimination based on race,
> color, sex, or national origin under this section:

This paragraph is then followed by a list of divisive concepts or claims, mostly verbatim 
from the executive order. So no need to repeate them here.

But there are a couple of interesting twists. The first:

> (b) Paragraph (a) may not be construed to prohibit
discussion of the concepts listed therein as part of a course of
training or instruction, provided such training or instruction
is given in an objective manner without endorsement of the
concepts.

This is, on its face, reassuring. Discussions about race, discrimination, racism, etc. are not banned.
The point is to make sure these discussions do not push divisive concepts. In another section, in fact, the H7B bill describes a few discussion topics in the school curriculum and lists this:

> Instructional personnel may facilitate
> discussions and use curricula to address, in an age-appropriate
> manner, how the individual freedoms of persons have been
> infringed by slavery, racial oppression, racial segregation, and
> racial discrimination, as well as topics relating to the
> enactment and enforcement of laws resulting in racial
> oppression, racial segregation, and racial discrimination

This is, again, reassuring. The bill explitly states that instrucutors may cover topics such as racism, discrimination and racial oppression.  This is far from, as the ACLU put it, a ban on "classroom discussions about race, gender, and systemic
oppression". The potential chilling effect remains, but that is a different point. 

*UPDATE*: ACLU Florida describes in a 2022 [note](https://www.aclufl.org/sites/default/files/field_documents/aclu_fl_written_testimony_in_opposition-_hb_7_government_censorship_of_race_gender_discussions_judiciary_1.25.22.pdf) the HB7 like this:

> HB 7/SB 148 make it an unlawful employment practice for any employer
to engage in discussions, instruction, or training about race, gender,
national origin, and the impacts of slavery and patriarchal systems.

Quotations above from HB7 itself shows this isn't accurate. The bill itself invites
"discussions, instruction, or training about race" (well, so long as they do not push divisive concepts which, as we know, 
are not part of DEI trainings). So why this misrepresentation? 


# August 7, 2024

## Predicting the economy -- beyond standard economic modeling 

This seems like a great book to read:

- RWL: Farmer (2024), [Making Sense of Chaos: A Better Economics for a Better World](https://www.penguin.co.uk/books/284357/making-sense-of-chaos-by-farmer-j-doyne/9780241201978)

The key thesis. Standard economics work with mathematical models that rest of simple and artificial assumptions of rationality (say, maximization of expected utility).  These models are idealizations and have no traction in the real world. So economics predictive power is weak. What is the alternative? Simulate! Collect data about every relevant aspect in the economy---employment, production, immigration, etc. data we have have more and more. Then, simulate agents and processes. Let the simulation run over time and see what happens. Intriguing yet also distopyc and scary.

Farmer in [this excellent interview](https://www.youtube.com/watch?v=cIQP0hJ920k) provides several interesting examples of how his simulations have actually worked and helped central banks and governments make decisions:

- RWL: simulation of Washington housing market - [paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4710928)
- RWL: simulation of UK housing market for the Bank of England - [paper](https://www.bankofengland.co.uk/working-paper/2016/macroprudential-policy-in-an-agent-based-model-of-the-uk-housing-market)
- RWL: simulation of UK economy during the pademic - [paper](https://www.sciencedirect.com/science/article/pii/S0165188922002317) and [newspaper piece](https://csh.ac.at/news/predicting-the-economic-downturn-during-the-pandemic/)

He claims he managed to accurately predict a drop in UK GDP during the pandemic! This is all very impressive. This simulation approach, however, is resisted by mainstream economics. 

Farmer has a company -- [Macrocosmos](https://www.macrocosm.group/)that uses simulations to make predictions useful for policymakers, businesses, financial analysts, etc., with a focus on the climate change transition and the decarbonization of the economy. 

# August 21, 2024

## What is equality before labor?

Chapter 9 of [Equality: The History of an Elusive Idea](https://www.amazon.com/Equality-History-Darrin-M-McMahon/dp/0465093930) discusses how Italian fascism and German nazism were socialist movements interested in establishing equality. But what equality, exactly? 

Liberalism championed equality before the law. Italian fascism champions equality before labor. See 1927 [Carta del Lavoro](https://polyarchy.org/basta/documenti/carta.lavoro.1927.html):

> IV. Nel contratto collettivo di lavoro trova la sua espressione concreta la solidarietà fra i vari fattori della produzione, mediante la conciliazione degli opposti interessi dei datori di lavoro e dei lavoratori e la loro subordinazione agli interessi superiori della produzione.

> VI. Le associazioni professionali legalmente riconosciute, assicurano l'uguaglianza giuridica tra i datori di lavoro e i lavoratori, mantengono la disciplina della produzione e del lavoro e ne promuovono il perfezionamento.

This is hard to understand, but recent suggests economic inequalities did increase during Italian facism:

- Giacomo Gabbuti (2020), [A Noi! Income Inequality and Italian Fascism: Evidence
from Labour and Top Income Shares](https://ora.ox.ac.uk/objects/uuid:eeddbb9c-7b39-4347-91ff-fa25fa2c44bf/files/scc08hg081)

Interestingly, [Corradi Gini](https://en.wikipedia.org/wiki/Corrado_Gini) -- from the Gini coefficient -- was a fascist!



# Agust 26, 2024

I'll follow up on some earlier thoughts about the right theory of uncertainty, especially in relation to the Rootclaim debate about the origins of covid. See earlier post on August 6, 2024. 

One of the judges wrote a detailed report in which he claimed that Bayesianism is not the right theory to handle uncertainty. 

- Eric Stansifer, [Rootclaim covid-19 origins debate: Final decision](https://ermsta.com/r/covid_decision_20240217.pdf)

## Problem 1: Biased selection of the evidence 

Consider this scenario (pp. 20-21):

> Suppose you suspect something about your senator is quite odd, and perhaps they are not human at all, but rather secretly a lizard from space. To test this, you collect 100 pieces of data that inform the question. For many of these data points you know what to expect for humans: how tall are they, how much do they weigh, shapes of facial features, etc.

> Predictably, even if you have been completely fair in your data collection – all 100 data points are accurate, and you did not specifically seek out information that you know will be odd – if you are naive with your analysis in certain ways you will invariably conclude that they are a lizard.

How so? You could pick one feature that happens to have a low p-value, then conclude it is evidence againt the null (=not a lizard).
This p-hacking. Look hard enough and you'll find evudence against teh null. Burt what about Bayesian reasoning?

> Bayesian reasoning is capable of exactly the same error. For each of these observations you compute a Bayes factor. Half of them are less anomalous than average (Bayes factor 1) and half of them are more anomalous than average. They are only weakly anomalous – a 1 in
2 coincidence each, so Bayes factor 2 – but with 50 such pieces of weak evidence your total Bayes factor is 2^{50}, totally overwhelming any prior you had against secret space lizards.

The general point is clear, but the discussion is odd. Presumably, we'll have some evidence for Lizardness (in short, L) and some evidence against it. Say 50 features favor L and 50 do not. So the balance of evidence should be even. If the prior for L are low, the posterior probability of L will be low. Or most features could go against L, so the evidece against L will be overwhelming.   

The quotation instead assumes that 50 features could be weakely anomalous, with Bayes factor of 2. So, combined, the Bayes factor is 2^{50}, which is overwheliing evidence for L. But what about the other features? Why assume that their Bayes factor is merely 1? Why not 1/2 so that, combined, we have 1/2^{50}? The author admits that much when he writes (p. 21):

> However let us be a little less reckless; after all, all of those less anomalous observations
should have had a Bayes factor smaller than 1 because they are evidence for humanity.

Then, Stansifer assumes that we find out about these feature somewhat randomly and so their associated Bayes factors are uniformly distributed in the interval [0, 1].  So, some feature will favor L and other go against L. In the end, aggregating them, we will either have very strong evidence for L or against L. This is also odd. We cannot assume that we pick the values from a unifirm interval [0, 1]. Evidence isn't produced randomly so long as it tracks reality. The mechanism that generates the evidence must be "biased" for or against L -- that will depeden on what reality is like. Otherwise evidence is worthless.

Next, Stansifer adds (p. 22):

> However, what happens if we have a slight bias? Indeed even if all of our data points are individually fair, we might be biased about which data points we collect. Suppose we conveniently overlook half the data in favor of humanity; so we have two thirds
for lizards, and one thirds for humans.

The point here is clear, and I completely agree. (The earlier discussion seemed muddled, or I could not follow it.) If we are biased in the selection of the evidence -- without knowing it! -- the evidence might support conclusion L very strongly, while in fact that might be due, not to the truth of L, but to the biased selection of the evidence.

This point is sensible, but it isn't a problem for Bayesianism per se. Any formalism or method to assess evidence will face this problem. So we have:

(Task 1) assess the *available* evidence foir/against a hypothesis H
(Task 2) assess whether evidence collection was fair, unbiased, etc.

Bayesianism can carry out Task 1, but clearly cannot carry out Task 2, and we should be wary of that. What are some remedies? Here is Stansifer again (p. 22):

> If instead of a haphazard collection of observations one makes a collection of evidence that is in some way canonical it is much harder to introduce bias; say, one considers all fingers, but only fingers.

> ... if a hypothesis can be broken down into subparts, each necessary for the hypothesis as a whole to hold, then there is less potential for bias in the selection of evidence, though there may remain disagreement about the numbers assigned to the evidence or what
breakdown into subparts is cleanest.

These are very good points, but none would be incompatible with Bayesianism. Yes, we should agree on types of evidence to look at beforehand, prior to knowing their content. For example, in a trial, to questiokn a witness prior to knowing what they are going to say; or run a test prior to knowing the test results; etc. This guards us againt biased selection of evidence. Not a problem for Bayesian, but also, not a problem that Bayesianism can address. 

Later in critizing (p. 26) one of Rootclaim calculations, Stansifer points out that -- even granting that the probabilities assigned to assess the evidence are right  -- the choice if the evidence seemed at hoc and thus not convicing:

> even if all the numbers shown here are completely correct, I am not persuaded by the conclusion. The listed observations do not represent a canonical series of necessary events that must occur under the hypothesis .... one could argue that the choice of observations was ... unmotivated. Rather, the listed observations appear to be a miscellany of loosely related things that happened in the context of the HSM outbreak and seemed vaguely odd.

I have mixed feelings about this point. First, it is odd to dismiss evidenvce because it is not canonical or not what one woud expect. Evidence can be shown to be irrelevant or fabricated, but dmissing it is odd. Second, evidence is presented by both parties and the adversarial format should take care of possible biases in evidenbce selection, at least assuming one party has no greater access to evidenbce than the other (and there is not resona for that in the Rootclaim debate). Third, the task is to assess teh likelihood of hyptheses beased on the evidence available, not based on what evidence should have been presented but was not. On the other hand, I see the point, that a biased selection of the evidence could lead to the wrong results. 

## Problem 2: Recklessly aggregating weak evidence

The second pronblem -- related to the first -- is that Bayesianism allows for reckless aggregation of weak evidence that can yield overwhelming evidence. Why is this a problem?

Stansifer  comments on Rootclaim Bayesian computation, summarized in the table on page 27. Basically, we have a bunch of items of evidence, each with a Bayes factors (greater or smaller than 1), which are then aggregated. Total Bayes factor is very high, favoring lab leak. Here again (p. 27):

> Half of that weight comes from three pieces of evidence: the 12nct insert, CGGCGG , and the location of the first SSE (sum 8.882). These three pieces of evidence are claimed to be strong and deserve commensurate analysis. The other half comes from eight different pieces of evidence that are individually weak and appear ad hoc.

> This argument ... bears some resemblance to the space lizard argument, and observations seem to be selected primarily on the basis of how much they stand out rather than any canonical or complete collection of evidence. This is fine if the observations really stand out – a factor of 50 is not bad, and you will be hard pressed to turn up many factors of 50 by chance. But Rootclaim includes five factors of 2 or less in their favor, and these should be plentiful to find for any hypothesis, true or false.


This is again the earlier point about possible biases in the selection of the evidence. But there is a new important point being made here. That is, it is okay to select very strong evidence in favor of one's hypothesis. But when the individual items are weak evidence, this is more worrisome, becaue as we know, even weak pieces of evidence when combined, can become overwhelming. And this may be totally artificial. 

Not sure how to develop this further, but worth thinmign about more. It seems that for Bayesian many pieces of weak evidence versus one piece of strong evidence would be indistinguishable (assuming independence).  Stansifer think not. The risk of evidence selection bias with weak evidence is greater than with one single, strong item of evidence. 



## Problem 3: Lack of an explanation

The third problem is stated less clear in the report. So I am not quite sure if I am getting this right.





